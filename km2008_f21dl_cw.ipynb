{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Kyle Mckay - F21DL Coursework Portfolio\n",
    "===\n",
    "\n",
    "1. [Data Set Choice](#h1)\n",
    "2. [Visualization and Initial Data Exploration](#h2)\n",
    "    1. [Class Distribution](#h2_0)\n",
    "    1. [Direct Comparison](#h2_1)\n",
    "    2. [Conversion to Pixel Data](#h2_2)\n",
    "    3. [Average Images](#h2_3)\n",
    "    4. [Standard Deviation](#h2_4)\n",
    "3. [Acknowledgement](#ack)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initalise variables and functions used throughout the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_dir = 'DATA' \n",
    "img_dir = f'{data_dir}/images'\n",
    "\n",
    "# Utility method to plot numpy greyscale pixel matrices side by side for comparison\n",
    "def multi_plot(*imgs):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # TODO add multiple rows if many images\n",
    "    for i, avg in enumerate(imgs, 1):\n",
    "        title, dat = avg\n",
    "        ax = fig.add_subplot(1, len(imgs), i)\n",
    "        ax.imshow(dat, vmin=0, vmax=255, cmap='Greys_r')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Functional approach to collapsing 3rd order numpy greyscale pixel tensors using certain methods (e.g. mean)\n",
    "def collapse_img(full_mat, fn = np.mean, size = (300, 180)):\n",
    "    # Apply desired function\n",
    "    collapsed_img = fn(full_mat, axis = 0)\n",
    "    \n",
    "    # Reshap back to a matrix\n",
    "    return collapsed_img.reshape(size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a id=\"h1\">Data Set Choice</a>\n",
    "\n",
    "I chose to work with the FGVC-Aircraft data set (Maji et al.) because:\n",
    "\n",
    "- It is an image dataset and I'm interested in computer vision and image processing techniques.\n",
    "- The data set is intended for use as a multiclass classification problem, which provides an interesting level of complexity above binary classification and below multi-label classification.\n",
    "- There is granularity to the classes in the data set. With 41 manufacturers providing plenty of instances (image files) to work with for each.\n",
    "- The images are not provided in a uniform size or aspect ratio, which adds some complexity to homogenising and reducing the data in preprocessing to meet computational constraints.\n",
    "- The data provenance is clearly stated and acceptable for my research/learning purposes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a id=\"h2\">Visualization and Initial Data Exploration</a>\n",
    "\n",
    "## <a id=\"h2_0\">Class Distribution</a>\n",
    "\n",
    "I first want to get a sense for the number of instances there are per manufacturer since I know there are 100 images per aircraft model (the highest level of granularity), but have no sense for how evenly distributed those are among the lower class granularity levels.\n",
    "\n",
    "This is important since for training purposes I want my data to have an approximately even distribution to avoid biasing classification results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Data set provides text files listing the label that applies to each image\n",
    "img_labels = pd.read_csv(\n",
    "    f'{data_dir}/images_manufacturer_train.txt',\n",
    "    sep=' ', header=None, \n",
    "    names=['Image', 'Class'],\n",
    "    skip_blank_lines=True,\n",
    ")\n",
    "\n",
    "# Interested in classes with at least 100 instances (reasonable quantity)\n",
    "class_counts = img_labels['Class'].value_counts()\n",
    "class_counts = class_counts[class_counts >= 100]\n",
    "class_counts\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Boeing       733\n",
       "Airbus       434\n",
       "Embraer      233\n",
       "McDonnell    232\n",
       "de           167\n",
       "Canadair     134\n",
       "Cessna       133\n",
       "British      133\n",
       "Douglas      133\n",
       "Lockheed     102\n",
       "Fokker       100\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evidently there is not an even distribution of the manufacturer classes. TODO: Drop classes, drop images?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Size Distribution\n",
    "\n",
    "I next want to get a sense for how homogeneous the images are in terms of their dimensions. This is relevant to check if preprocessing needs to be done and, if so, which approach I will take."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Only interested in images with sufficient number of class instances\n",
    "all_imgs = img_labels[img_labels['Class'].isin(class_counts.keys())]['Image']\n",
    "\n",
    "\n",
    "sizes = []\n",
    "for fn in all_imgs:\n",
    "    # File names are padded with 0 to 7 digits\n",
    "    img = cv2.imread(f'{img_dir}/{fn:07}.jpg')\n",
    "\n",
    "    # Skip missing files for now\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    sizes.append(img.shape[:2])\n",
    "sizes = pd.DataFrame(sizes, columns=['Height', 'Width'])\n",
    "\n",
    "sizes.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2534.000000</td>\n",
       "      <td>2534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>751.729282</td>\n",
       "      <td>1105.763220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116.229313</td>\n",
       "      <td>168.916645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>434.000000</td>\n",
       "      <td>775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>693.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>700.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>812.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1188.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Height        Width\n",
       "count  2534.000000  2534.000000\n",
       "mean    751.729282  1105.763220\n",
       "std     116.229313   168.916645\n",
       "min     434.000000   775.000000\n",
       "25%     693.000000  1024.000000\n",
       "50%     700.000000  1024.000000\n",
       "75%     812.000000  1200.000000\n",
       "max    1188.000000  1600.000000"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I can see from the dimension descriptions that the images vary in size by a factor of ~2 in width and ~3 in height. They will need to be homogenised to a standard size so that the features (pixels) corrolate for later processing.\n",
    "\n",
    "Thankfully, the data set provides bounding boxes for the aircraft in each image, so I next want to find the minimum and maximum dimensions for those as I can use them to determine how I will approach preprocessing these images to standard dimensions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## <a id=\"h2_1\">Direct Comparison</a>\n",
    "\n",
    "The following code pulls 3 random sample images from each class for an initial direct visual comparison.\n",
    "\n",
    "It's clear from a quick visual inspection that the pollen carrying bees have distinct features (the pollen) on either side of their abdomen which isn't present in the other images. This suggests to me it should be fine to process the images in greyscale and reduce the number of features for efficiency since they should still be distinguishable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a id=\"h2_2\">Conversion to Pixel Data</a>\n",
    "\n",
    "The following script is converting greyscale versions of the image files into a 3rd order tensor with $n\\times m$ elements. $n$ is the number of observations and $m$ is the number of pixels (features). The element values represent the pixel shade."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a id=\"h2_3\">Average Images</a>\n",
    "\n",
    "By averaging the pixel data for all of a given class, I can get a sense for the regions which are common to each class. It's not as clear as before, but there's still an obvious presence on either side of the abdomen for the pollen carrying class which isn't present in the other images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Average Images Difference\n",
    "\n",
    "The difference between the classes becomes clearer by taking the difference of these two averaged images. Now it's much more obvious that one class (pollen carrier) has a distinct region of pixels in the lower left and a less distinct region in the lower right."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a id=\"h2_4\">Standard Deviation</a>\n",
    "\n",
    "To get a sense of the pixel regions which vary the most in each class, the same reasoning of averaging can be applied, but instead taking the standard deviation. The resulting images aren't as clear, but here I can see a lot more varience in those lower left and right regions for the pollen carrying class. This reinforces my understanding of the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a id=\"ack\">Acknowledgement</a>\n",
    "\n",
    "FGVC-Aircraft data set:\n",
    "\n",
    "Fine-Grained Visual Classification of Aircraft, S. Maji, J. Kannala, E. Rahtu, M. Blaschko, A. Vedaldi, [arXiv.org](https://arxiv.org/abs/1306.5151), 2013\n",
    "\n",
    "Image Data Exploration Code adapted from: [https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2](https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('dmml': conda)"
  },
  "interpreter": {
   "hash": "238e84a50bd85e6896fa827f44429e675207169bc4aaa396c9b81005f50b7995"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}